{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from model.FCGS_model import FCGS\n",
    "\n",
    "def fidelity_loss(outputs, gt):\n",
    "    # 定义fidelity loss\n",
    "    return torch.nn.functional.mse_loss(outputs, gt)\n",
    "\n",
    "def rate_loss():\n",
    "    # 定义rate loss\n",
    "    return torch.tensor(0.0)\n",
    "\n",
    "def loss_fun(outputs, gt):\n",
    "    return fidelity_loss(outputs, gt) + rate_loss()\n",
    "\n",
    "model = FCGS()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "iterations = 1000\n",
    "for i in range(iterations):\n",
    "    model.train()\n",
    "    inputs = None  # 这里需要加载输入数据\n",
    "    gt = None  # 这里需要加载ground truth数据\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_fun(outputs, gt)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f'Iteration {i}, Loss: {loss.item()}')\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'fcgs_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0196)\n",
      "Input shape: torch.Size([16, 100])\n",
      "Output shape: torch.Size([16, 100])\n",
      "tensor(0.0167, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# GDN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GDN1D(nn.Module):\n",
    "    def __init__(self, num_features, inverse=False, beta_min=1e-6, gamma_init=0.1):\n",
    "        super(GDN1D, self).__init__()\n",
    "        self.inverse = inverse\n",
    "        self.beta_min = beta_min\n",
    "        self.gamma_init = gamma_init\n",
    "        # 可学习的参数\n",
    "        self.beta = nn.Parameter(torch.ones(num_features))\n",
    "        self.gamma = nn.Parameter(torch.eye(num_features) * gamma_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 确保 beta 不小于 beta_min\n",
    "        beta = torch.max(self.beta, torch.tensor(self.beta_min, dtype=torch.float32, device=x.device))\n",
    "        # 计算归一化因子\n",
    "        norm_pool = torch.einsum('bi,ij->bj', x ** 2, self.gamma) + beta\n",
    "        norm_pool = torch.sqrt(norm_pool)\n",
    "\n",
    "        if self.inverse:\n",
    "            output = x * norm_pool\n",
    "        else:\n",
    "            output = x / norm_pool\n",
    "\n",
    "        return output\n",
    "\n",
    "# 示例使用\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入数据的特征数量\n",
    "    num_features = 100\n",
    "    # 创建 GDN 层\n",
    "    gdn_layer = GDN1D(num_features)\n",
    "    # 生成随机 1 维输入数据\n",
    "    input_data = torch.randn(16, num_features)\n",
    "    # 前向传播\n",
    "    print(input_data.mean())\n",
    "    output = gdn_layer(input_data)\n",
    "    print(\"Input shape:\", input_data.shape)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    print(output.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 15])\n",
      "Output shape: torch.Size([1, 15])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MaskedConv1d(nn.Conv1d):\n",
    "    r\"\"\"Masked 1D convolution implementation, mask future \"unseen\" pixels.\n",
    "    Useful for building auto-regressive network components.\n",
    "\n",
    "    Inherits the same arguments as a `nn.Conv1d`. Use `mask_type='A'` for the\n",
    "    first layer (which also masks the \"current pixel\"), `mask_type='B'` for the\n",
    "    following layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, mask_type=\"A\", **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        if mask_type not in (\"A\", \"B\"):\n",
    "            raise ValueError(f'Invalid \"mask_type\" value \"{mask_type}\"')\n",
    "\n",
    "        # 初始化掩码\n",
    "        self.register_buffer(\"mask\", torch.ones_like(self.weight.data))\n",
    "        _, _, w = self.mask.size()\n",
    "\n",
    "        # 根据掩码类型设置掩码\n",
    "        center = w // 2\n",
    "        if mask_type == \"A\":\n",
    "            self.mask[:, :, center:] = 0\n",
    "        else:\n",
    "            self.mask[:, :, center + 1:] = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 应用掩码到权重上\n",
    "        self.weight.data *= self.mask\n",
    "        return super().forward(x)\n",
    "\n",
    "\n",
    "# 示例使用\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入通道数\n",
    "    in_channels = 1\n",
    "    # 输出通道数\n",
    "    out_channels = 1\n",
    "    # 卷积核大小\n",
    "    kernel_size = 3\n",
    "    # 步长\n",
    "    stride = 1\n",
    "    # 填充\n",
    "    padding = 1\n",
    "    # 输入序列长度\n",
    "    sequence_length = 15\n",
    "\n",
    "    # 创建 MaskedConv1d 层\n",
    "    masked_conv1d_layer = MaskedConv1d(in_channels, out_channels, kernel_size, stride, padding, mask_type=\"A\")\n",
    "\n",
    "    # 生成随机输入数据\n",
    "    input_data = torch.randn(in_channels, sequence_length)\n",
    "\n",
    "    # 前向传播\n",
    "    output = masked_conv1d_layer(input_data)\n",
    "\n",
    "    \n",
    "    print(\"Input shape:\", input_data.shape)\n",
    "    print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCGS_D(\n",
      "  (cur_gaussians): GaussianModel()\n",
      "  (FeatureExtractor): Sequential(\n",
      "    (0): Linear(in_features=56, out_features=256, bias=True)\n",
      "    (1): GDN1D()\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): GDN1D()\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (MotionEncoder): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): GDN1D()\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): GDN1D()\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (MotionDecoder): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): GDN1D()\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): GDN1D()\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (MotionPriorEncoder): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): GDN1D()\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): GDN1D()\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (MotionPriorDecoder): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): GDN1D()\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): GDN1D()\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (AutoRegressiveMotion): Sequential(\n",
      "    (0): MaskedConv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (2): MaskedConv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (4): MaskedConv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tinycudann as tcnn\n",
    "from gaussian_renderer import GaussianModel\n",
    "from model.encodings_cuda import STE_multistep, encoder_gaussian, decoder_gaussian, encoder_gaussian_chunk, decoder_gaussian_chunk, \\\n",
    "    encoder_gaussian_mixed, decoder_gaussian_mixed, encoder_gaussian_mixed_chunk, decoder_gaussian_mixed_chunk,\\\n",
    "    encoder_factorized, decoder_factorized, encoder_factorized_chunk, decoder_factorized_chunk\n",
    "from model.entropy_models import Entropy_factorized\n",
    "\n",
    "\n",
    "class FCGS_D(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(FCGS_D, self).__init__()\n",
    "        self.args = args\n",
    "        self.Q = 1 # args.Q\n",
    "        self.gof_size = 10 # args.gof_size\n",
    "        self.gaussian_position_dim = 3\n",
    "        self.gaussian_feature_dim = 56 # args.gaussian_feature_dim\n",
    "        self.motion_dim = 256  # args.motion_dim # 256\n",
    "        self.hidden_dim = 256 # args.hidden_dim # 256\n",
    "        self.lat_dim = 256 # args.lat_dim # 256\n",
    "        self.GDN = GDN1D\n",
    "        self.init_test_gaussians()\n",
    "\n",
    "        self.FeatureExtractor = nn.Sequential(\n",
    "            nn.Linear(self.gaussian_feature_dim, self.hidden_dim),\n",
    "            self.GDN(self.hidden_dim),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            self.GDN(self.hidden_dim),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.lat_dim)\n",
    "        )\n",
    "\n",
    "        self.MotionEstimator = None\n",
    "\n",
    "        self.MotionEncoder = nn.Sequential(\n",
    "            nn.Linear(self.motion_dim, self.hidden_dim),\n",
    "            self.GDN(self.hidden_dim),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            self.GDN(self.hidden_dim),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.lat_dim),\n",
    "        )\n",
    "\n",
    "        self.MotionDecoder = nn.Sequential(\n",
    "            nn.Linear(self.lat_dim, self.hidden_dim),\n",
    "            self.GDN(self.hidden_dim),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            self.GDN(self.hidden_dim),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.motion_dim),\n",
    "        )\n",
    "\n",
    "        self.MotionPriorEncoder = nn.Sequential(\n",
    "            nn.Linear(self.lat_dim, self.hidden_dim),\n",
    "            self.GDN(self.hidden_dim),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            self.GDN(self.hidden_dim),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.lat_dim),\n",
    "        )\n",
    "\n",
    "        self.MotionPriorDecoder = nn.Sequential(\n",
    "            nn.Linear(self.lat_dim, self.hidden_dim),\n",
    "            self.GDN(self.hidden_dim),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            self.GDN(self.hidden_dim),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.lat_dim),\n",
    "        )\n",
    "\n",
    "        self.AutoRegressiveMotion = nn.Sequential(\n",
    "            MaskedConv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1, mask_type=\"A\"),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            MaskedConv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1, mask_type=\"A\"),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            MaskedConv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1, mask_type=\"A\"),\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.EntropyParametersMotion = nn.Sequential(\n",
    "            nn.Linear(self.lat_dim * 2, self.hidden_dim),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim, 2)\n",
    "        )\n",
    "\n",
    "        self.EntropyFactorizedMotion = Entropy_factorized(self.lat_dim, self.Q)\n",
    "\n",
    "\n",
    "    def quantize(self, x, Q=1, test_flag=False):\n",
    "        if test_flag:\n",
    "            x_q = STE_multistep.apply(x, Q)\n",
    "        else:\n",
    "            # add uniform noise to simulate quantization while training\n",
    "            x_q = x + torch.empty_like(x).uniform_(-0.5, 0.5) * Q  \n",
    "        return self.clamp(x_q, Q)\n",
    "    \n",
    "    def clamp(self, x, Q):\n",
    "        x[torch.isnan(x)] = 0 \n",
    "        x_mean = x.mean().detach()\n",
    "        x_min = x_mean - 15_000 * Q\n",
    "        x_max = x_mean + 15_000 * Q\n",
    "        x = torch.clamp(x, min=x_min.detach(), max=x_max.detach())\n",
    "        return x\n",
    "\n",
    "    def MotionCompensation(self, lat_motion, pre_gaussians):\n",
    "        ...\n",
    "\n",
    "    def refresh_gaussians(self, pre_gaussian_path, cur_gaussian_path, sh_degree = 3):\n",
    "        self.cur_gaussians = self.read_gaussian_file(cur_gaussian_path, sh_degree)\n",
    "        self.pre_gaussians = self.read_gaussian_file(pre_gaussian_path, sh_degree)\n",
    "\n",
    "    def read_gaussian_file(self, file_path, sh_degree = 3):\n",
    "        with torch.no_grad():\n",
    "            gaussians = GaussianModel(sh_degree)\n",
    "            gaussians.load_ply(file_path)\n",
    "        return gaussians\n",
    "    \n",
    "    def init_test_gaussians(self, sh_degree = 3):\n",
    "        self.cur_gaussians = self.read_gaussian_file('/SDD_D/zwk/output/cook_spinach-3-ori/init_3dgs.ply')\n",
    "\n",
    "    def compress(self):\n",
    "        ...\n",
    "\n",
    "    def decompress(self):\n",
    "        ...\n",
    "        \n",
    "    def forward(self):\n",
    "        est_motion = self.MotionEstimator() # I-NGP in 3DGStream / MLP in Deformable-GS / Hexplane in 4D-GS\n",
    "        y_motion = self.MotionEncoder(est_motion) # N, latent_dim\n",
    "        y_hat_motion = self.quantize(y_motion, Q=1, test_flag=False)\n",
    "        ctx_params_motion = self.AutoRegressiveMotion(y_hat_motion) # N, latent_dim\n",
    "\n",
    "        z_motion = self.MotionPriorEncoder(y_motion) # N, latent_dim\n",
    "        z_hat_motion = self.quantize(z_motion, Q=1, test_flag=False)\n",
    "        params_motion = self.MotionPriorDecoder(z_hat_motion) # N, latent_dim\n",
    "\n",
    "        distribution_motion = self.EntropyParametersMotion(torch.cat((y_motion, z_motion), dim=1)) # N, 2\n",
    "        mean_motion, std_motion = torch.chunk(distribution_motion, 2, dim=1)\n",
    "        std_motion = F.softplus(std_motion) + 1e-6\n",
    "\n",
    "        # TODO 精细化\n",
    "        bits_motion = encoder_gaussian_chunk(y_hat_motion, mean_motion, std_motion, self.Q, 'motion.b')\n",
    "        bits_prior_motion = encoder_factorized_chunk(z_hat_motion, self.EntropyFactorizedMotion._logits_cumulative, self.Q, 'motion_prior.b')\n",
    "\n",
    "        return ctx_params_motion, params_motion\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = None\n",
    "\n",
    "    init_3dgs = '/SDD_D/zwk/output/cook_spinach-3-ori/init_3dgs.ply'\n",
    "    ntc = '/SDD_D/zwk/output/cook_spinach-3-ori/NTCs/NTC_000000.pth'\n",
    "    model = FCGS_D(args)\n",
    "    # 查看模型结构\n",
    "    # print(model)\n",
    "\n",
    "    # ctx_params_motion, params_motion = model()\n",
    "    # print(ctx_params_motion.shape, params_motion.shape)\n",
    "    # print(ctx_params_motion.mean(), params_motion.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.5018e-03, 3.6340e-02, 1.2356e-01, 3.0157e-01, 5.4679e-01, 7.7488e-01,\n",
      "         9.1811e-01, 9.7882e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [2.3675e-24, 1.3898e-14, 1.6869e-07, 4.7385e-03, 4.6516e-01, 9.9223e-01,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [2.9773e-36, 2.1199e-21, 1.1863e-10, 5.9014e-04, 4.3953e-01, 9.9836e-01,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [6.0210e-39, 1.0779e-21, 1.0287e-09, 6.4013e-03, 8.4490e-01, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.2384e-41, 1.2593e-21, 1.5149e-08, 5.4975e-02,\n",
      "         9.9043e-01, 1.0000e+00],\n",
      "        [1.5983e-02, 4.3148e-02, 9.9274e-02, 1.9596e-01, 3.3485e-01, 5.0120e-01,\n",
      "         6.6734e-01, 8.0570e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1324e-13,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [5.7178e-05, 8.7145e-04, 8.1125e-03, 4.6794e-02, 1.7113e-01, 4.1190e-01,\n",
      "         6.9301e-01, 8.9092e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [2.4295e-19, 1.6980e-08, 1.6838e-02, 8.9828e-01, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [1.7982e-04, 2.9729e-03, 2.6590e-02, 1.3218e-01, 3.8252e-01, 6.9792e-01,\n",
      "         9.0918e-01, 9.8434e-01],\n",
      "        [7.6794e-14, 7.0468e-10, 1.1517e-06, 3.4290e-04, 1.9434e-02, 2.3087e-01,\n",
      "         7.2362e-01, 9.7277e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [1.3392e-19, 1.9952e-14, 4.0892e-10, 1.1703e-06, 4.8058e-04, 2.9934e-02,\n",
      "         3.2208e-01, 8.3097e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 7.0570e-33, 3.8785e-12, 3.5880e-02, 9.9941e-01, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [1.6082e-02, 6.8817e-02, 2.0413e-01, 4.3281e-01, 6.8740e-01, 8.7414e-01,\n",
      "         9.6438e-01, 9.9308e-01],\n",
      "        [3.1442e-02, 7.1786e-02, 1.4339e-01, 2.5212e-01, 3.9342e-01, 5.5052e-01,\n",
      "         6.9999e-01, 8.2167e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6936e-02, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1018e-21, 2.1051e-01, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [7.6448e-14, 4.2937e-08, 4.4360e-04, 9.7873e-02, 7.6929e-01, 9.9717e-01,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 3.9951e-33, 2.3973e-21, 2.7038e-12, 6.0633e-06, 3.1716e-02,\n",
      "         7.4633e-01, 9.9927e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2178e-07,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 7.2184e-35, 1.9014e-19, 9.3932e-09, 1.0637e-02,\n",
      "         8.4534e-01, 9.9999e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [2.5287e-37, 8.7604e-07, 9.9919e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6383e-03,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [4.5410e-07, 2.4136e-05, 6.4743e-04, 8.8844e-03, 6.3794e-02, 2.4921e-01,\n",
      "         5.6740e-01, 8.4530e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [3.7165e-15, 1.0147e-10, 3.8799e-07, 2.1292e-04, 1.7614e-02, 2.4574e-01,\n",
      "         7.6726e-01, 9.8413e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9513e-35, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 4.6947e-38, 4.6690e-17, 7.7595e-05, 7.7267e-01, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [5.9377e-35, 3.7177e-21, 5.3517e-11, 1.9560e-04, 2.6264e-01, 9.8856e-01,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [1.6034e-03, 7.1266e-03, 2.5324e-02, 7.2409e-02, 1.6810e-01, 3.2084e-01,\n",
      "         5.1237e-01, 7.0104e-01],\n",
      "        [5.6634e-12, 1.3829e-07, 2.4247e-04, 3.2948e-02, 4.2492e-01, 9.2792e-01,\n",
      "         9.9907e-01, 1.0000e+00],\n",
      "        [1.0277e-21, 2.2527e-13, 3.2340e-07, 3.3243e-03, 3.2592e-01, 9.6497e-01,\n",
      "         9.9998e-01, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [4.7852e-04, 4.9876e-03, 3.2120e-02, 1.3043e-01, 3.4525e-01, 6.2855e-01,\n",
      "         8.5410e-01, 9.6249e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [2.5377e-16, 1.0019e-11, 5.7331e-08, 4.8521e-05, 6.3167e-03, 1.3786e-01,\n",
      "         6.2321e-01, 9.5709e-01],\n",
      "        [1.5655e-05, 3.8306e-04, 5.1471e-03, 3.8629e-02, 1.6656e-01, 4.3294e-01,\n",
      "         7.3568e-01, 9.2350e-01],\n",
      "        [1.3859e-11, 4.8440e-08, 3.0779e-05, 3.6698e-03, 8.7659e-02, 4.8820e-01,\n",
      "         9.0254e-01, 9.9563e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.4337e-10, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [2.2652e-05, 6.0367e-04, 8.2952e-03, 6.0070e-02, 2.3801e-01, 5.5123e-01,\n",
      "         8.3404e-01, 9.6499e-01],\n",
      "        [2.2321e-04, 3.4693e-03, 2.9476e-02, 1.4067e-01, 3.9508e-01, 7.0717e-01,\n",
      "         9.1251e-01, 9.8490e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [5.3136e-05, 1.1138e-02, 2.4339e-01, 8.1454e-01, 9.9352e-01, 9.9998e-01,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [2.0730e-29, 2.3722e-18, 4.6731e-10, 1.7112e-04, 1.4874e-01, 9.3284e-01,\n",
      "         9.9997e-01, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5835e-03, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [1.3543e-09, 1.5668e-06, 3.6856e-04, 1.8358e-02, 2.1116e-01, 6.8583e-01,\n",
      "         9.6168e-01, 9.9888e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [2.6183e-01, 3.4998e-01, 4.4708e-01, 5.4748e-01, 6.4492e-01, 7.3368e-01,\n",
      "         8.0957e-01, 8.7048e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00]], device='cuda:0')\n",
      "1136\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import arithmetic\n",
    "import os\n",
    "\n",
    "chunk_size_cuda = 10000\n",
    "\n",
    "def encoder_gaussian(x, mean, scale, Q, file_name='tmp.b'):\n",
    "    # should be single dimension\n",
    "    assert file_name.endswith('.b')\n",
    "    assert len(x.shape) == 1\n",
    "    if not isinstance(Q, torch.Tensor):\n",
    "        Q = torch.tensor([Q], dtype=mean.dtype, device=mean.device).repeat(mean.shape[0])\n",
    "    x_int_round = torch.round(x / Q)  # [100]\n",
    "    max_value = x_int_round.max()\n",
    "    min_value = x_int_round.min()\n",
    "\n",
    "    lower = arithmetic.calculate_cdf(\n",
    "        mean,\n",
    "        scale,\n",
    "        Q,\n",
    "        min_value,\n",
    "        max_value\n",
    "    )\n",
    "\n",
    "    print(lower)\n",
    "\n",
    "    x_int_round_idx = (x_int_round - min_value).to(torch.int16)\n",
    "    (byte_stream_torch, cnt_torch) = arithmetic.arithmetic_encode(\n",
    "        x_int_round_idx,\n",
    "        lower,\n",
    "        chunk_size_cuda,\n",
    "        int(lower.shape[0]),\n",
    "        int(lower.shape[1])\n",
    "    )\n",
    "    cnt_bytes = cnt_torch.cpu().numpy().tobytes()\n",
    "    byte_stream_bytes = byte_stream_torch.cpu().numpy().tobytes()\n",
    "    len_cnt_bytes = len(cnt_bytes)\n",
    "    with open(file_name, 'wb') as fout:\n",
    "        fout.write(min_value.to(torch.float32).cpu().numpy().tobytes())\n",
    "        fout.write(max_value.to(torch.float32).cpu().numpy().tobytes())\n",
    "        fout.write(np.array([len_cnt_bytes]).astype(np.int32).tobytes())\n",
    "        fout.write(cnt_bytes)\n",
    "        fout.write(byte_stream_bytes)\n",
    "    bit_len = (len(byte_stream_bytes) + len(cnt_bytes))*8 + 32 * 3\n",
    "    return bit_len\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    mean = torch.randn(100).cuda()\n",
    "    scale = torch.randn(100).cuda()\n",
    "    x = torch.randn(100).cuda()\n",
    "    Q = 1\n",
    "    bit_len = encoder_gaussian(x, mean, scale, Q)\n",
    "    print(bit_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['ad_fe', 'ad_op', 'ad_sc', 'ad_ro', 'Encoder_mask.0.weight', 'Encoder_mask.0.bias', 'Encoder_mask.2.weight', 'Encoder_mask.2.bias', 'Encoder_mask.4.weight', 'Encoder_mask.4.bias', 'Encoder_fea.0.weight', 'Encoder_fea.0.bias', 'Encoder_fea.2.weight', 'Encoder_fea.2.bias', 'Encoder_fea.4.weight', 'Encoder_fea.4.bias', 'Encoder_fea.6.weight', 'Encoder_fea.6.bias', 'Decoder_fea.0.weight', 'Decoder_fea.0.bias', 'Decoder_fea.2.weight', 'Decoder_fea.2.bias', 'Decoder_fea.4.weight', 'Decoder_fea.4.bias', 'Decoder_fea.6.weight', 'Decoder_fea.6.bias', 'head_f_dc.0.weight', 'head_f_dc.0.bias', 'head_f_dc.2.weight', 'head_f_dc.2.bias', 'head_f_rst.0.weight', 'head_f_rst.0.bias', 'head_f_rst.2.weight', 'head_f_rst.2.bias', 'latdim_2_griddim_fea.0.weight', 'latdim_2_griddim_fea.0.bias', 'context_analyzer_fea.0.weight', 'context_analyzer_fea.0.bias', 'context_analyzer_fea.2.weight', 'context_analyzer_fea.2.bias', 'context_analyzer_fea.4.weight', 'context_analyzer_fea.4.bias', 'context_analyzer_feq.0.weight', 'context_analyzer_feq.0.bias', 'context_analyzer_feq.2.weight', 'context_analyzer_feq.2.bias', 'context_analyzer_feq.4.weight', 'context_analyzer_feq.4.bias', 'context_analyzer_geo.0.weight', 'context_analyzer_geo.0.bias', 'context_analyzer_geo.2.weight', 'context_analyzer_geo.2.bias', 'context_analyzer_geo.4.weight', 'context_analyzer_geo.4.bias', 'feq_channel_ctx.mean_d0', 'feq_channel_ctx.scale_d0', 'feq_channel_ctx.prob_d0', 'feq_channel_ctx.MLP_d0.0.weight', 'feq_channel_ctx.MLP_d0.0.bias', 'feq_channel_ctx.MLP_d0.2.weight', 'feq_channel_ctx.MLP_d0.2.bias', 'feq_channel_ctx.MLP_d0.4.weight', 'feq_channel_ctx.MLP_d0.4.bias', 'feq_channel_ctx.MLP_d1.0.weight', 'feq_channel_ctx.MLP_d1.0.bias', 'feq_channel_ctx.MLP_d1.2.weight', 'feq_channel_ctx.MLP_d1.2.bias', 'feq_channel_ctx.MLP_d1.4.weight', 'feq_channel_ctx.MLP_d1.4.bias', 'fea_channel_ctx.mean_d0', 'fea_channel_ctx.scale_d0', 'fea_channel_ctx.prob_d0', 'fea_channel_ctx.MLP_d0.0.weight', 'fea_channel_ctx.MLP_d0.0.bias', 'fea_channel_ctx.MLP_d0.2.weight', 'fea_channel_ctx.MLP_d0.2.bias', 'fea_channel_ctx.MLP_d0.4.weight', 'fea_channel_ctx.MLP_d0.4.bias', 'fea_channel_ctx.MLP_d1.0.weight', 'fea_channel_ctx.MLP_d1.0.bias', 'fea_channel_ctx.MLP_d1.2.weight', 'fea_channel_ctx.MLP_d1.2.bias', 'fea_channel_ctx.MLP_d1.4.weight', 'fea_channel_ctx.MLP_d1.4.bias', 'fea_channel_ctx.MLP_d2.0.weight', 'fea_channel_ctx.MLP_d2.0.bias', 'fea_channel_ctx.MLP_d2.2.weight', 'fea_channel_ctx.MLP_d2.2.bias', 'fea_channel_ctx.MLP_d2.4.weight', 'fea_channel_ctx.MLP_d2.4.bias', 'Encoder_fea_hyp.0.weight', 'Encoder_fea_hyp.0.bias', 'Encoder_fea_hyp.2.weight', 'Encoder_fea_hyp.2.bias', 'Encoder_fea_hyp.4.weight', 'Encoder_fea_hyp.4.bias', 'Decoder_fea_hyp.0.weight', 'Decoder_fea_hyp.0.bias', 'Decoder_fea_hyp.2.weight', 'Decoder_fea_hyp.2.bias', 'Decoder_fea_hyp.4.weight', 'Decoder_fea_hyp.4.bias', 'Encoder_feq_hyp.0.weight', 'Encoder_feq_hyp.0.bias', 'Encoder_feq_hyp.2.weight', 'Encoder_feq_hyp.2.bias', 'Encoder_feq_hyp.4.weight', 'Encoder_feq_hyp.4.bias', 'Decoder_feq_hyp.0.weight', 'Decoder_feq_hyp.0.bias', 'Decoder_feq_hyp.2.weight', 'Decoder_feq_hyp.2.bias', 'Decoder_feq_hyp.4.weight', 'Decoder_feq_hyp.4.bias', 'Encoder_geo_hyp.0.weight', 'Encoder_geo_hyp.0.bias', 'Encoder_geo_hyp.2.weight', 'Encoder_geo_hyp.2.bias', 'Encoder_geo_hyp.4.weight', 'Encoder_geo_hyp.4.bias', 'Decoder_geo_hyp.0.weight', 'Decoder_geo_hyp.0.bias', 'Decoder_geo_hyp.2.weight', 'Decoder_geo_hyp.2.bias', 'Decoder_geo_hyp.4.weight', 'Decoder_geo_hyp.4.bias', 'EF_fea.matrix', 'EF_fea.bias', 'EF_fea.factor', 'EF_fea._matrices.0', 'EF_fea._matrices.1', 'EF_fea._matrices.2', 'EF_fea._matrices.3', 'EF_fea._bias.0', 'EF_fea._bias.1', 'EF_fea._bias.2', 'EF_fea._bias.3', 'EF_fea._factor.0', 'EF_fea._factor.1', 'EF_fea._factor.2', 'EF_feq.matrix', 'EF_feq.bias', 'EF_feq.factor', 'EF_feq._matrices.0', 'EF_feq._matrices.1', 'EF_feq._matrices.2', 'EF_feq._matrices.3', 'EF_feq._bias.0', 'EF_feq._bias.1', 'EF_feq._bias.2', 'EF_feq._bias.3', 'EF_feq._factor.0', 'EF_feq._factor.1', 'EF_feq._factor.2', 'EF_geo.matrix', 'EF_geo.bias', 'EF_geo.factor', 'EF_geo._matrices.0', 'EF_geo._matrices.1', 'EF_geo._matrices.2', 'EF_geo._matrices.3', 'EF_geo._bias.0', 'EF_geo._bias.1', 'EF_geo._bias.2', 'EF_geo._bias.3', 'EF_geo._factor.0', 'EF_geo._factor.1', 'EF_geo._factor.2', 'EF_op.matrix', 'EF_op.bias', 'EF_op.factor', 'EF_op._matrices.0', 'EF_op._matrices.1', 'EF_op._matrices.2', 'EF_op._matrices.3', 'EF_op._bias.0', 'EF_op._bias.1', 'EF_op._bias.2', 'EF_op._bias.3', 'EF_op._factor.0', 'EF_op._factor.1', 'EF_op._factor.2', 'EF_sc.matrix', 'EF_sc.bias', 'EF_sc.factor', 'EF_sc._matrices.0', 'EF_sc._matrices.1', 'EF_sc._matrices.2', 'EF_sc._matrices.3', 'EF_sc._bias.0', 'EF_sc._bias.1', 'EF_sc._bias.2', 'EF_sc._bias.3', 'EF_sc._factor.0', 'EF_sc._factor.1', 'EF_sc._factor.2', 'EF_ro.matrix', 'EF_ro.bias', 'EF_ro.factor', 'EF_ro._matrices.0', 'EF_ro._matrices.1', 'EF_ro._matrices.2', 'EF_ro._matrices.3', 'EF_ro._bias.0', 'EF_ro._bias.1', 'EF_ro._bias.2', 'EF_ro._bias.3', 'EF_ro._factor.0', 'EF_ro._factor.1', 'EF_ro._factor.2'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2199,  0.0228, -0.2152, -0.1741, -0.0614, -0.0755, -0.1351, -0.0658,\n",
       "        -0.1244, -0.4855, -0.1434, -0.1962, -0.0422, -0.4207, -0.0133, -0.1403,\n",
       "        -0.2316, -0.2603, -0.1911, -0.0319, -0.0466, -0.0643,  0.0294, -0.0397,\n",
       "        -0.2160,  0.0190, -0.1236,  0.0410,  0.1044, -0.0074, -0.1154, -0.0603,\n",
       "        -0.0627, -0.0903, -0.1829, -0.4057, -0.2135,  0.0430,  0.0401, -0.3041,\n",
       "         0.0220, -0.2577, -0.1143, -0.3101, -0.1599, -0.3278, -0.0194, -0.2106,\n",
       "        -0.1497, -0.1500,  0.1130, -0.0709, -0.2816, -0.1030,  0.0338, -0.1919,\n",
       "        -0.5007, -0.0663, -0.0362, -0.2168, -0.1294,  0.0091, -0.0842, -0.0747,\n",
       "        -0.1157, -0.1401,  0.0516, -0.1424, -0.0477, -0.0292,  0.0224, -0.1151,\n",
       "         0.0307, -0.0398, -0.3047,  0.0506, -0.0277, -0.3021, -0.0702, -0.5035,\n",
       "        -0.0821,  0.0174, -0.3068,  0.0021, -0.2357, -0.1727, -0.1807, -0.1134,\n",
       "         0.0648, -0.1752,  0.0254, -0.1737, -0.0982, -0.1247, -0.1661, -0.0044,\n",
       "         0.1510, -0.1707,  0.1030, -0.0888, -0.1335,  0.0123, -0.2463, -0.0027,\n",
       "        -0.1487, -0.1631,  0.0677, -0.1108, -0.1596, -0.0293, -0.4114,  0.0050,\n",
       "        -0.0264, -0.1490, -0.0561,  0.0326, -0.1472, -0.2725, -0.1949, -0.0985,\n",
       "        -0.1032, -0.1850, -0.1512, -0.2625,  0.1696, -0.2674, -0.1577, -0.0770,\n",
       "         0.0068, -0.0890, -0.2623, -0.0582, -0.1996, -0.3033, -0.5629, -0.1176,\n",
       "        -0.3522, -0.2270, -0.1404, -0.0376, -0.1834, -0.0218, -0.1078, -0.1054,\n",
       "         0.0025, -0.2764, -0.0621, -0.1176, -0.0828, -0.0321,  0.0936, -0.4628,\n",
       "        -0.2276, -0.5137, -0.2942,  0.0080, -0.1195, -0.0891, -0.2157, -0.4927,\n",
       "        -0.1146, -0.4142, -0.1251,  0.0011, -0.3451, -0.4415,  0.0156, -0.2377,\n",
       "        -0.0449, -0.2388, -0.1440, -0.1519,  0.0319, -0.1496, -0.2192, -0.2785,\n",
       "        -0.1626,  0.0133, -0.1218,  0.0444, -0.1640, -0.0280,  0.0091, -0.1395,\n",
       "        -0.1535, -0.2511, -0.0779, -0.1369, -0.3263, -0.0917,  0.0520, -0.2803,\n",
       "         0.0106, -0.1563,  0.0176, -0.0535, -0.2896, -0.4723,  0.0470, -0.0783,\n",
       "        -0.4138,  0.0424, -0.2464, -0.3208, -0.5359,  0.0212, -0.1126, -0.1668,\n",
       "        -0.1716,  0.0633, -0.2011,  0.0113, -0.2807, -0.1881, -0.1369, -0.1397,\n",
       "        -0.4444, -0.1910, -0.1955, -0.1655, -0.0406, -0.1265, -0.0298, -0.2168,\n",
       "        -0.0478, -0.3528, -0.0964,  0.1325,  0.0559, -0.2475, -0.1245,  0.1025,\n",
       "        -0.1712, -0.4895, -0.0637, -0.2567, -0.4185,  0.0029, -0.0434, -0.1315,\n",
       "        -0.0818, -0.2048, -0.0686, -0.0287, -0.2821, -0.1895, -0.0891, -0.2411,\n",
       "        -0.3952, -0.1517, -0.2563, -0.0226, -0.3239, -0.1755, -0.2505,  0.0489])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取pkl文件，修改参数\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "\n",
    "def modify_and_save_pkl(input_file_path, output_file_path, name_mapping):\n",
    "    \"\"\"\n",
    "    该函数用于加载一个pkl文件，修改其中参数的名称，并将修改后的数据保存为新的pkl文件。\n",
    "\n",
    "    :param input_file_path: 输入pkl文件的路径\n",
    "    :param output_file_path: 输出pkl文件的路径\n",
    "    :param name_mapping: 一个字典，用于指定参数名称的映射关系，键为原名称，值为新名称\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 打开输入的pkl文件并加载数据\n",
    "        with open(input_file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        # 如果加载的数据是字典类型\n",
    "        if isinstance(data, dict):\n",
    "            new_data = {}\n",
    "            for key, value in data.items():\n",
    "                # 根据名称映射关系修改键名\n",
    "                new_key = name_mapping.get(key, key)\n",
    "                new_data[new_key] = value\n",
    "        else:\n",
    "            # 若数据不是字典类型，直接使用原数据\n",
    "            new_data = data\n",
    "\n",
    "        # 打开输出的pkl文件并保存修改后的数据\n",
    "        with open(output_file_path, 'wb') as f:\n",
    "            pickle.dump(new_data, f)\n",
    "\n",
    "        print(f\"参数名称修改完成，新文件已保存到 {output_file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"未找到输入文件: {input_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件时出现错误: {e}\")\n",
    "\n",
    "pkl_path = 'checkpoints/checkpoint_0.0001.pkl'\n",
    "\n",
    "# 读取pkl文件\n",
    "state_dict = torch.load(pkl_path, map_location='cpu')\n",
    "\n",
    "# 查看state_dict的key\n",
    "print(state_dict.keys())\n",
    "\n",
    "# 示例使用\n",
    "input_file = pkl_path\n",
    "output_file = 'output.pkl'\n",
    "# 定义参数名称的映射关系\n",
    "name_mapping = {\n",
    "    'old_name_1': 'new_name_1',\n",
    "    'old_name_2': 'new_name_2'\n",
    "}\n",
    "\n",
    "# modify_and_save_pkl(input_file, output_file, name_mapping)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcgs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
